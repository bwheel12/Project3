{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import numpy\n",
    "from scripts import NN\n",
    "import math as m\n",
    "from scripts import io\n",
    "importlib.reload(NN)\n",
    "importlib.reload(io)\n",
    "import random as rand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "these chunks implement the auto encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup = [8,3,8]\n",
    "alpha = 0.5\n",
    "lamba = 0 #any weight decay fails to converge\n",
    "batch_size = 500 #how many examples to step through before updating weights\n",
    "bias  = 1 #actually should get rid of this\n",
    "auto_NN = NN.NeuralNetwork(setup,NN.activation,alpha,lamba,batch_size,bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num batch is  1 11 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 11 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 11 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\r"
     ]
    }
   ],
   "source": [
    "epoch_number = 100000\n",
    "cost_list = []\n",
    "batch_number = 1\n",
    "input_size   = 8\n",
    "for j in range(epoch_number):\n",
    "    training_batch = numpy.zeros((input_size))\n",
    "    rand_index = int(numpy.ceil(rand.random()*8)-1)\n",
    "    training_batch[rand_index] = 1\n",
    "    training_batch = [training_batch]\n",
    "    training_answer = training_batch\n",
    "    auto_NN.get_training_set(training_batch,training_answer)\n",
    "    cost_list.append(auto_NN.batch_descent())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final output [array([0.96814126, 0.9821459 , 0.006298  ]), array([2.56776456e-02, 9.71834316e-01, 8.22715032e-06, 1.07607523e-09,\n",
      "       1.35757495e-02, 1.00335423e-05, 1.38091441e-02, 3.59502177e-06])]\n",
      "final edge matrices [array([[ 5.53478965,  3.843963  ,  3.89209979, -4.05165839, -4.09690669,\n",
      "        -4.44539717,  2.98373378, -4.08034993],\n",
      "       [ 4.89311589,  4.27185859, -5.06170982, -3.90993464,  3.23319095,\n",
      "         4.10327712, -3.72912144, -4.03676307],\n",
      "       [ 5.29490458, -4.69328623,  3.6008267 ,  3.12199185, -3.61293901,\n",
      "         4.34254491, -4.23053348, -4.15712481]]), array([[ 6.86110011,  6.60259312,  6.76405494],\n",
      "       [ 7.38071237,  7.33849491, -8.22353967],\n",
      "       [ 7.45689332, -8.44748469,  7.30932123],\n",
      "       [-8.57539023, -8.63990563,  8.31995405],\n",
      "       [-8.71077379,  8.32781108, -8.52528248],\n",
      "       [-8.12052993,  7.33157369,  7.46535297],\n",
      "       [ 8.45310311, -8.63593901, -8.87516541],\n",
      "       [-8.51219028, -8.29086983, -8.41653809]])]\n",
      "final biases [array([-0.42989681, -0.26435166, -0.36791909]), array([-16.80594531, -10.76017206, -10.67676032,  -3.91450752,\n",
      "        -3.97797529, -10.89543861,  -3.91466887,   3.90089688])]\n"
     ]
    }
   ],
   "source": [
    "auto_NN.get_single_input([0,1,0,0,0,0,0,0])\n",
    "auto_NN.feedforward()\n",
    "print(\"final output\",auto_NN.layer_a)\n",
    "print(\"final edge matrices\",auto_NN.edge_matrices)\n",
    "print(\"final biases\",auto_NN.biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "these chunks implement a simple classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup = [8,3,1]\n",
    "alpha = 0.5\n",
    "lamba = 0 #0.1 is good\n",
    "batch_size = 10\n",
    "bias  = 1\n",
    "classy_NN = NN.NeuralNetwork(setup,NN.activation,alpha,lamba,batch_size,bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num batch is  10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\r"
     ]
    }
   ],
   "source": [
    "epoch_number = 10000\n",
    "cost_list = []\n",
    "batch_number = 1\n",
    "input_size   = 8\n",
    "output_size  = 1\n",
    "for j in range(epoch_number):\n",
    "    training_list = []\n",
    "    answer_list   = []\n",
    "    for k in range(batch_size):\n",
    "        training_batch = numpy.zeros((input_size))\n",
    "        training_answer = numpy.zeros((output_size))\n",
    "        rand_index = int(numpy.ceil(rand.random()*8)-1)\n",
    "        training_batch[rand_index] = 1\n",
    "        training_list.append(training_batch)\n",
    "        if rand_index > 3: \n",
    "            training_answer[0] = 1\n",
    "        answer_list.append(training_answer)\n",
    "    classy_NN.get_training_set(training_list,answer_list)\n",
    "    cost_list.append(classy_NN.batch_descent())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final output [array([0.27759873, 0.18524872, 0.8651533 ]), array([0.98150834])]\n",
      "final edge matrices [array([[ 0.88900945,  0.88109641,  0.88143009,  0.8764948 , -0.89631189,\n",
      "        -0.9042514 , -0.9022423 , -0.90002653],\n",
      "       [ 1.41579784,  1.4289509 ,  1.4264069 ,  1.42003672, -1.44845237,\n",
      "        -1.45069935, -1.44494507, -1.44170441],\n",
      "       [-1.80175996, -1.79553422, -1.80124664, -1.8141863 ,  1.81969393,\n",
      "         1.82520277,  1.81919401,  1.82331101]]), array([[-2.52025957, -4.32524218,  5.94789733]])]\n",
      "final biases [array([-0.05637755, -0.0394791 ,  0.03545709]), array([0.32679422])]\n"
     ]
    }
   ],
   "source": [
    "classy_NN.get_single_input([0,0,0,0,0,0,0,1])\n",
    "classy_NN.feedforward()\n",
    "print(\"final output\",classy_NN.layer_a)\n",
    "print(\"final edge matrices\",classy_NN.edge_matrices)\n",
    "print(\"final biases\",classy_NN.biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "these chunks implement classification of rap1 sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup = [68,20,10,1]\n",
    "alpha = 0.5\n",
    "lamba = 0 #0.1 is good\n",
    "batch_size = 10\n",
    "bias  = 1\n",
    "rap1_NN = NN.NeuralNetwork(setup,NN.activation,alpha,lamba,batch_size,bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "rap1_pos_list = io.import_positives('data/rap1-lieb-positives.txt')\n",
    "genom_neg_list = io.import_negatives('data/yeast-upstream-1k-negative.fa',17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num batch is  14 20 20 20\r"
     ]
    }
   ],
   "source": [
    "epoch_number = 1000 # the number of times through the whole data set\n",
    "cost_list = []\n",
    "for j in range(epoch_number):\n",
    "    batch_cycles = int(numpy.ceil(len(rap1_pos_list)/batch_size)) #the number of batches in data set for a given batch size\n",
    "    \n",
    "    for k in range(batch_cycles):\n",
    "        if k < batch_cycles-1:\n",
    "            training_list = rap1_pos_list[(k)*batch_size:(k+1)*batch_size]\n",
    "            rand_index    = int(numpy.floor(rand.random()*(len(genom_neg_list)-batch_size)))\n",
    "            #print(\"rand index is\", rand_index)\n",
    "            training_list = training_list + genom_neg_list[rand_index:rand_index+batch_size]\n",
    "            training_list = io.one_hot_encode(training_list)\n",
    "            #print(\"training list norm is\",len(training_list))\n",
    "            answer_list   = numpy.ones((batch_size))\n",
    "            answer_list   = numpy.concatenate((answer_list,numpy.zeros((batch_size))))\n",
    "        if k == batch_cycles-1:\n",
    "            size_temp     = len(rap1_pos_list[k*batch_size:])\n",
    "            training_list = rap1_pos_list[(k)*batch_size:]\n",
    "            and_index    = int(numpy.floor(rand.random()*(len(genom_neg_list)-size_temp)))\n",
    "            training_list = training_list + genom_neg_list[rand_index:rand_index+size_temp]\n",
    "            training_list = io.one_hot_encode(training_list)\n",
    "            #print(\"training list short is \",len(training_list))\n",
    "            answer_list   = numpy.ones((size_temp))\n",
    "            answer_list   = numpy.concatenate((answer_list,numpy.zeros((size_temp))))\n",
    "        \n",
    "        #print(k)\n",
    "        #print(training_list)\n",
    "        #print(answer_list)\n",
    "        rap1_NN.get_training_set(training_list,answer_list)\n",
    "        cost_list.append(rap1_NN.batch_descent())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0.\n",
      " 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      "final output [array([0.72319344, 0.28714093, 0.28497669, 0.27978773, 0.28315328,\n",
      "       0.72424022, 0.37582386, 0.69824529, 0.27460251, 0.71363269,\n",
      "       0.72863722, 0.66322559, 0.71871777, 0.28020072, 0.62201452,\n",
      "       0.54475883, 0.72369206, 0.27006025, 0.28953511, 0.55903068]), array([0.67196826, 0.69040805, 0.43810345, 0.30264392, 0.45560298,\n",
      "       0.38119166, 0.28439742, 0.27007927, 0.75096965, 0.69859341]), array([0.96623319])]\n",
      "final edge matrices [array([[-0.043852  , -0.13032737, -0.06073451, ..., -0.11350527,\n",
      "         0.00894413, -0.06817113],\n",
      "       [ 0.11456571,  0.28351729,  0.13932156, ...,  0.2409979 ,\n",
      "        -0.00817406,  0.15974676],\n",
      "       [ 0.03684616,  0.12152747,  0.08217631, ...,  0.12099487,\n",
      "        -0.02434519,  0.06933944],\n",
      "       ...,\n",
      "       [ 0.04956917,  0.16091529,  0.08290743, ...,  0.14412372,\n",
      "        -0.01688638,  0.07538669],\n",
      "       [ 0.08641195,  0.26255409,  0.14416821, ...,  0.25891018,\n",
      "        -0.00219226,  0.16708098],\n",
      "       [-0.00199925, -0.01182286,  0.01188246, ..., -0.00654382,\n",
      "         0.00174418,  0.01058148]]), array([[ 2.13385121e-01, -4.27202839e-01, -2.40932763e-01,\n",
      "        -2.77376807e-01, -3.33789595e-01,  2.62233727e-01,\n",
      "        -5.51063955e-02,  1.69399218e-01, -2.92098875e-01,\n",
      "         1.62932939e-01,  3.11564302e-01,  9.75882999e-02,\n",
      "         4.71110162e-01, -2.09434633e-01,  6.39666843e-02,\n",
      "         2.22382956e-02,  2.47812463e-01, -2.47106761e-01,\n",
      "        -4.12188935e-01,  3.12129925e-02],\n",
      "       [ 2.55264048e-01, -5.39023356e-01, -2.71414396e-01,\n",
      "        -3.70257300e-01, -4.10091637e-01,  3.27916092e-01,\n",
      "        -9.61277884e-02,  2.02590491e-01, -3.91227054e-01,\n",
      "         1.87610495e-01,  4.05257697e-01,  9.45958305e-02,\n",
      "         5.75198036e-01, -3.01280293e-01,  6.97576182e-02,\n",
      "         2.01004164e-02,  3.21952611e-01, -3.29189015e-01,\n",
      "        -5.08709718e-01,  1.42476987e-02],\n",
      "       [-4.04323829e-02,  9.14179800e-02,  6.13433074e-02,\n",
      "         6.66181103e-02,  9.33151535e-02, -7.77179412e-02,\n",
      "         2.23490920e-02, -3.83545038e-02,  6.80820082e-02,\n",
      "        -3.62893054e-02, -1.07833251e-01, -3.86370294e-02,\n",
      "        -1.06227411e-01,  5.65160210e-02, -3.39198240e-02,\n",
      "        -7.73854614e-03, -9.58160799e-02,  5.95647542e-02,\n",
      "         8.39908657e-02, -6.73505408e-03],\n",
      "       [-2.77068997e-01,  5.99447322e-01,  3.15964842e-01,\n",
      "         3.84029283e-01,  4.63513068e-01, -3.58146045e-01,\n",
      "         1.08683182e-01, -2.01858421e-01,  4.29427382e-01,\n",
      "        -2.00985908e-01, -4.10894635e-01, -1.18098322e-01,\n",
      "        -6.30499519e-01,  3.12732379e-01, -7.96124372e-02,\n",
      "        -2.49846471e-02, -3.44530857e-01,  3.51120310e-01,\n",
      "         5.84191790e-01, -2.05213195e-02],\n",
      "       [-4.97689615e-02,  7.34791060e-02,  3.49344529e-02,\n",
      "         4.17737698e-02,  4.02358797e-02, -7.09152489e-02,\n",
      "         1.84530316e-02, -2.23013954e-02,  4.29752340e-02,\n",
      "        -3.77170032e-02, -5.51824812e-02, -1.92749078e-02,\n",
      "        -7.35947061e-02,  3.79964995e-02, -1.85292882e-02,\n",
      "        -1.75525173e-02, -4.37061883e-02,  4.22680009e-02,\n",
      "         5.92671878e-02, -1.13495536e-02],\n",
      "       [-1.09695211e-01,  2.06777320e-01,  9.25000571e-02,\n",
      "         1.55021430e-01,  1.79269901e-01, -1.47994563e-01,\n",
      "         2.73428660e-02, -7.27610060e-02,  1.66086656e-01,\n",
      "        -1.01769565e-01, -1.72331586e-01, -7.55850922e-02,\n",
      "        -2.32468224e-01,  1.15548990e-01, -3.23556056e-02,\n",
      "        -2.62686586e-02, -1.53174764e-01,  1.16514707e-01,\n",
      "         2.06719668e-01, -4.37482406e-02],\n",
      "       [-3.39002886e-01,  7.02370313e-01,  3.88778296e-01,\n",
      "         4.69371101e-01,  5.83986915e-01, -4.37750818e-01,\n",
      "         1.26084472e-01, -2.37128049e-01,  5.31381595e-01,\n",
      "        -2.39714429e-01, -5.08728402e-01, -1.32000692e-01,\n",
      "        -7.59931514e-01,  4.07849574e-01, -8.73829130e-02,\n",
      "        -7.19864618e-03, -4.27315036e-01,  4.26111060e-01,\n",
      "         7.23456353e-01, -1.31712748e-02],\n",
      "       [-3.66667912e-01,  8.19140294e-01,  4.55782171e-01,\n",
      "         5.45670598e-01,  6.58670588e-01, -4.95221223e-01,\n",
      "         1.55431082e-01, -2.77096089e-01,  6.12209042e-01,\n",
      "        -2.64956032e-01, -5.81442499e-01, -1.58966816e-01,\n",
      "        -8.64023557e-01,  4.53163054e-01, -9.37153184e-02,\n",
      "        -1.18155713e-02, -4.69873132e-01,  5.16055362e-01,\n",
      "         8.16264582e-01,  2.25240695e-04],\n",
      "       [ 4.24133851e-01, -1.00969211e+00, -5.28584939e-01,\n",
      "        -6.50750838e-01, -7.94493184e-01,  5.81065064e-01,\n",
      "        -1.99493092e-01,  3.10590099e-01, -7.28055672e-01,\n",
      "         3.27016569e-01,  6.68010635e-01,  1.74016469e-01,\n",
      "         1.02048720e+00, -5.55834143e-01,  9.44911988e-02,\n",
      "        -2.43795276e-03,  5.52406597e-01, -6.00595460e-01,\n",
      "        -9.81757011e-01,  1.89497995e-02],\n",
      "       [ 2.81130728e-01, -5.75235045e-01, -3.16005083e-01,\n",
      "        -3.92173641e-01, -4.82437883e-01,  3.73835267e-01,\n",
      "        -1.00335092e-01,  2.06989135e-01, -4.19530290e-01,\n",
      "         2.14958358e-01,  4.20227839e-01,  1.00828136e-01,\n",
      "         6.52166397e-01, -3.45766186e-01,  6.95379450e-02,\n",
      "         1.04881818e-02,  3.65886934e-01, -3.64723144e-01,\n",
      "        -5.90491304e-01, -5.20465656e-03]]), array([[ 1.25135056,  1.58205249, -0.24430365, -1.63272415, -0.14597603,\n",
      "        -0.56331447, -2.04153396, -2.37516237,  3.01059123,  1.76512138]])]\n",
      "final biases [array([-0.11724432,  0.36281196,  0.13428433,  0.20012879,  0.27830288,\n",
      "       -0.21426963,  0.01834426, -0.08108038,  0.23964685, -0.08382616,\n",
      "       -0.24276449, -0.02226441, -0.4252971 ,  0.13731137, -0.00709213,\n",
      "       -0.02592068, -0.1969624 ,  0.16875715,  0.34264359, -0.01081471]), array([-0.0315921 , -0.04613644, -0.0038208 ,  0.0529795 ,  0.00463781,\n",
      "       -0.02147576,  0.11409446,  0.13341848, -0.15272412, -0.06319792]), array([0.0313238])]\n"
     ]
    }
   ],
   "source": [
    "pos_test = io.one_hot_encode([rap1_pos_list[100]])\n",
    "#pos_test = numpy.transpose(pos_test)\n",
    "pos_test = pos_test[0]\n",
    "print(pos_test)\n",
    "rap1_NN.get_single_input(pos_test)\n",
    "rap1_NN.feedforward()\n",
    "print(\"final output\",rap1_NN.layer_a)\n",
    "print(\"final edge matrices\",rap1_NN.edge_matrices)\n",
    "print(\"final biases\",rap1_NN.biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0.]\n",
      "final output [array([0.32732717, 0.8831644 , 0.66909429, 0.73257699, 0.81254937,\n",
      "       0.23729313, 0.50680384, 0.39369131, 0.78288627, 0.3912135 ,\n",
      "       0.19688687, 0.45731655, 0.08831314, 0.67772868, 0.46447022,\n",
      "       0.47584724, 0.25408838, 0.7247504 , 0.87436957, 0.49208279]), array([0.18940927, 0.12656611, 0.5758532 , 0.89561108, 0.54758666,\n",
      "       0.65772405, 0.93830846, 0.95959232, 0.0210137 , 0.10012985]), array([0.00391271])]\n",
      "final edge matrices [array([[-0.043852  , -0.13032737, -0.06073451, ..., -0.11350527,\n",
      "         0.00894413, -0.06817113],\n",
      "       [ 0.11456571,  0.28351729,  0.13932156, ...,  0.2409979 ,\n",
      "        -0.00817406,  0.15974676],\n",
      "       [ 0.03684616,  0.12152747,  0.08217631, ...,  0.12099487,\n",
      "        -0.02434519,  0.06933944],\n",
      "       ...,\n",
      "       [ 0.04956917,  0.16091529,  0.08290743, ...,  0.14412372,\n",
      "        -0.01688638,  0.07538669],\n",
      "       [ 0.08641195,  0.26255409,  0.14416821, ...,  0.25891018,\n",
      "        -0.00219226,  0.16708098],\n",
      "       [-0.00199925, -0.01182286,  0.01188246, ..., -0.00654382,\n",
      "         0.00174418,  0.01058148]]), array([[ 2.13385121e-01, -4.27202839e-01, -2.40932763e-01,\n",
      "        -2.77376807e-01, -3.33789595e-01,  2.62233727e-01,\n",
      "        -5.51063955e-02,  1.69399218e-01, -2.92098875e-01,\n",
      "         1.62932939e-01,  3.11564302e-01,  9.75882999e-02,\n",
      "         4.71110162e-01, -2.09434633e-01,  6.39666843e-02,\n",
      "         2.22382956e-02,  2.47812463e-01, -2.47106761e-01,\n",
      "        -4.12188935e-01,  3.12129925e-02],\n",
      "       [ 2.55264048e-01, -5.39023356e-01, -2.71414396e-01,\n",
      "        -3.70257300e-01, -4.10091637e-01,  3.27916092e-01,\n",
      "        -9.61277884e-02,  2.02590491e-01, -3.91227054e-01,\n",
      "         1.87610495e-01,  4.05257697e-01,  9.45958305e-02,\n",
      "         5.75198036e-01, -3.01280293e-01,  6.97576182e-02,\n",
      "         2.01004164e-02,  3.21952611e-01, -3.29189015e-01,\n",
      "        -5.08709718e-01,  1.42476987e-02],\n",
      "       [-4.04323829e-02,  9.14179800e-02,  6.13433074e-02,\n",
      "         6.66181103e-02,  9.33151535e-02, -7.77179412e-02,\n",
      "         2.23490920e-02, -3.83545038e-02,  6.80820082e-02,\n",
      "        -3.62893054e-02, -1.07833251e-01, -3.86370294e-02,\n",
      "        -1.06227411e-01,  5.65160210e-02, -3.39198240e-02,\n",
      "        -7.73854614e-03, -9.58160799e-02,  5.95647542e-02,\n",
      "         8.39908657e-02, -6.73505408e-03],\n",
      "       [-2.77068997e-01,  5.99447322e-01,  3.15964842e-01,\n",
      "         3.84029283e-01,  4.63513068e-01, -3.58146045e-01,\n",
      "         1.08683182e-01, -2.01858421e-01,  4.29427382e-01,\n",
      "        -2.00985908e-01, -4.10894635e-01, -1.18098322e-01,\n",
      "        -6.30499519e-01,  3.12732379e-01, -7.96124372e-02,\n",
      "        -2.49846471e-02, -3.44530857e-01,  3.51120310e-01,\n",
      "         5.84191790e-01, -2.05213195e-02],\n",
      "       [-4.97689615e-02,  7.34791060e-02,  3.49344529e-02,\n",
      "         4.17737698e-02,  4.02358797e-02, -7.09152489e-02,\n",
      "         1.84530316e-02, -2.23013954e-02,  4.29752340e-02,\n",
      "        -3.77170032e-02, -5.51824812e-02, -1.92749078e-02,\n",
      "        -7.35947061e-02,  3.79964995e-02, -1.85292882e-02,\n",
      "        -1.75525173e-02, -4.37061883e-02,  4.22680009e-02,\n",
      "         5.92671878e-02, -1.13495536e-02],\n",
      "       [-1.09695211e-01,  2.06777320e-01,  9.25000571e-02,\n",
      "         1.55021430e-01,  1.79269901e-01, -1.47994563e-01,\n",
      "         2.73428660e-02, -7.27610060e-02,  1.66086656e-01,\n",
      "        -1.01769565e-01, -1.72331586e-01, -7.55850922e-02,\n",
      "        -2.32468224e-01,  1.15548990e-01, -3.23556056e-02,\n",
      "        -2.62686586e-02, -1.53174764e-01,  1.16514707e-01,\n",
      "         2.06719668e-01, -4.37482406e-02],\n",
      "       [-3.39002886e-01,  7.02370313e-01,  3.88778296e-01,\n",
      "         4.69371101e-01,  5.83986915e-01, -4.37750818e-01,\n",
      "         1.26084472e-01, -2.37128049e-01,  5.31381595e-01,\n",
      "        -2.39714429e-01, -5.08728402e-01, -1.32000692e-01,\n",
      "        -7.59931514e-01,  4.07849574e-01, -8.73829130e-02,\n",
      "        -7.19864618e-03, -4.27315036e-01,  4.26111060e-01,\n",
      "         7.23456353e-01, -1.31712748e-02],\n",
      "       [-3.66667912e-01,  8.19140294e-01,  4.55782171e-01,\n",
      "         5.45670598e-01,  6.58670588e-01, -4.95221223e-01,\n",
      "         1.55431082e-01, -2.77096089e-01,  6.12209042e-01,\n",
      "        -2.64956032e-01, -5.81442499e-01, -1.58966816e-01,\n",
      "        -8.64023557e-01,  4.53163054e-01, -9.37153184e-02,\n",
      "        -1.18155713e-02, -4.69873132e-01,  5.16055362e-01,\n",
      "         8.16264582e-01,  2.25240695e-04],\n",
      "       [ 4.24133851e-01, -1.00969211e+00, -5.28584939e-01,\n",
      "        -6.50750838e-01, -7.94493184e-01,  5.81065064e-01,\n",
      "        -1.99493092e-01,  3.10590099e-01, -7.28055672e-01,\n",
      "         3.27016569e-01,  6.68010635e-01,  1.74016469e-01,\n",
      "         1.02048720e+00, -5.55834143e-01,  9.44911988e-02,\n",
      "        -2.43795276e-03,  5.52406597e-01, -6.00595460e-01,\n",
      "        -9.81757011e-01,  1.89497995e-02],\n",
      "       [ 2.81130728e-01, -5.75235045e-01, -3.16005083e-01,\n",
      "        -3.92173641e-01, -4.82437883e-01,  3.73835267e-01,\n",
      "        -1.00335092e-01,  2.06989135e-01, -4.19530290e-01,\n",
      "         2.14958358e-01,  4.20227839e-01,  1.00828136e-01,\n",
      "         6.52166397e-01, -3.45766186e-01,  6.95379450e-02,\n",
      "         1.04881818e-02,  3.65886934e-01, -3.64723144e-01,\n",
      "        -5.90491304e-01, -5.20465656e-03]]), array([[ 1.25135056,  1.58205249, -0.24430365, -1.63272415, -0.14597603,\n",
      "        -0.56331447, -2.04153396, -2.37516237,  3.01059123,  1.76512138]])]\n",
      "final biases [array([-0.11724432,  0.36281196,  0.13428433,  0.20012879,  0.27830288,\n",
      "       -0.21426963,  0.01834426, -0.08108038,  0.23964685, -0.08382616,\n",
      "       -0.24276449, -0.02226441, -0.4252971 ,  0.13731137, -0.00709213,\n",
      "       -0.02592068, -0.1969624 ,  0.16875715,  0.34264359, -0.01081471]), array([-0.0315921 , -0.04613644, -0.0038208 ,  0.0529795 ,  0.00463781,\n",
      "       -0.02147576,  0.11409446,  0.13341848, -0.15272412, -0.06319792]), array([0.0313238])]\n"
     ]
    }
   ],
   "source": [
    "neg_test = io.one_hot_encode([genom_neg_list[100]])\n",
    "#pos_test = numpy.transpose(pos_test)\n",
    "neg_test = neg_test[0]\n",
    "print(neg_test)\n",
    "rap1_NN.get_single_input(neg_test)\n",
    "rap1_NN.feedforward()\n",
    "print(\"final output\",rap1_NN.layer_a)\n",
    "print(\"final edge matrices\",rap1_NN.edge_matrices)\n",
    "print(\"final biases\",rap1_NN.biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
