{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import numpy\n",
    "from scripts import NN\n",
    "import math as m\n",
    "from scripts import io\n",
    "importlib.reload(NN)\n",
    "importlib.reload(io)\n",
    "import random as rand\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "these chunks implement the auto encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup = [8,3,8]\n",
    "alpha = 0.5\n",
    "lamba = 0 #any weight decay fails to converge\n",
    "batch_size = 500 #how many examples to step through before updating weights\n",
    "bias  = 1 #actually should get rid of this\n",
    "auto_NN = NN.NeuralNetwork(setup,NN.activation,alpha,lamba,batch_size,bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num batch is  1 11 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 11 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 11 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\r"
     ]
    }
   ],
   "source": [
    "epoch_number = 100000\n",
    "cost_list = []\n",
    "batch_number = 1\n",
    "input_size   = 8\n",
    "for j in range(epoch_number):\n",
    "    training_batch = numpy.zeros((input_size))\n",
    "    rand_index = int(numpy.ceil(rand.random()*8)-1)\n",
    "    training_batch[rand_index] = 1\n",
    "    training_batch = [training_batch]\n",
    "    training_answer = training_batch\n",
    "    auto_NN.get_training_set(training_batch,training_answer)\n",
    "    cost_list.append(auto_NN.batch_descent())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final output [array([0.96814126, 0.9821459 , 0.006298  ]), array([2.56776456e-02, 9.71834316e-01, 8.22715032e-06, 1.07607523e-09,\n",
      "       1.35757495e-02, 1.00335423e-05, 1.38091441e-02, 3.59502177e-06])]\n",
      "final edge matrices [array([[ 5.53478965,  3.843963  ,  3.89209979, -4.05165839, -4.09690669,\n",
      "        -4.44539717,  2.98373378, -4.08034993],\n",
      "       [ 4.89311589,  4.27185859, -5.06170982, -3.90993464,  3.23319095,\n",
      "         4.10327712, -3.72912144, -4.03676307],\n",
      "       [ 5.29490458, -4.69328623,  3.6008267 ,  3.12199185, -3.61293901,\n",
      "         4.34254491, -4.23053348, -4.15712481]]), array([[ 6.86110011,  6.60259312,  6.76405494],\n",
      "       [ 7.38071237,  7.33849491, -8.22353967],\n",
      "       [ 7.45689332, -8.44748469,  7.30932123],\n",
      "       [-8.57539023, -8.63990563,  8.31995405],\n",
      "       [-8.71077379,  8.32781108, -8.52528248],\n",
      "       [-8.12052993,  7.33157369,  7.46535297],\n",
      "       [ 8.45310311, -8.63593901, -8.87516541],\n",
      "       [-8.51219028, -8.29086983, -8.41653809]])]\n",
      "final biases [array([-0.42989681, -0.26435166, -0.36791909]), array([-16.80594531, -10.76017206, -10.67676032,  -3.91450752,\n",
      "        -3.97797529, -10.89543861,  -3.91466887,   3.90089688])]\n"
     ]
    }
   ],
   "source": [
    "auto_NN.get_single_input([0,1,0,0,0,0,0,0])\n",
    "auto_NN.feedforward()\n",
    "print(\"final output\",auto_NN.layer_a)\n",
    "print(\"final edge matrices\",auto_NN.edge_matrices)\n",
    "print(\"final biases\",auto_NN.biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "these chunks implement a simple classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup = [8,3,1]\n",
    "alpha = 0.5\n",
    "lamba = 0 #0.1 is good\n",
    "batch_size = 10\n",
    "bias  = 1\n",
    "classy_NN = NN.NeuralNetwork(setup,NN.activation,alpha,lamba,batch_size,bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num batch is  10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\r"
     ]
    }
   ],
   "source": [
    "epoch_number = 10000\n",
    "cost_list = []\n",
    "batch_number = 1\n",
    "input_size   = 8\n",
    "output_size  = 1\n",
    "for j in range(epoch_number):\n",
    "    training_list = []\n",
    "    answer_list   = []\n",
    "    for k in range(batch_size):\n",
    "        training_batch = numpy.zeros((input_size))\n",
    "        training_answer = numpy.zeros((output_size))\n",
    "        rand_index = int(numpy.ceil(rand.random()*8)-1)\n",
    "        training_batch[rand_index] = 1\n",
    "        training_list.append(training_batch)\n",
    "        if rand_index > 3: \n",
    "            training_answer[0] = 1\n",
    "        answer_list.append(training_answer)\n",
    "    classy_NN.get_training_set(training_list,answer_list)\n",
    "    cost_list.append(classy_NN.batch_descent())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final output [array([0.27759873, 0.18524872, 0.8651533 ]), array([0.98150834])]\n",
      "final edge matrices [array([[ 0.88900945,  0.88109641,  0.88143009,  0.8764948 , -0.89631189,\n",
      "        -0.9042514 , -0.9022423 , -0.90002653],\n",
      "       [ 1.41579784,  1.4289509 ,  1.4264069 ,  1.42003672, -1.44845237,\n",
      "        -1.45069935, -1.44494507, -1.44170441],\n",
      "       [-1.80175996, -1.79553422, -1.80124664, -1.8141863 ,  1.81969393,\n",
      "         1.82520277,  1.81919401,  1.82331101]]), array([[-2.52025957, -4.32524218,  5.94789733]])]\n",
      "final biases [array([-0.05637755, -0.0394791 ,  0.03545709]), array([0.32679422])]\n"
     ]
    }
   ],
   "source": [
    "classy_NN.get_single_input([0,0,0,0,0,0,0,1])\n",
    "classy_NN.feedforward()\n",
    "print(\"final output\",classy_NN.layer_a)\n",
    "print(\"final edge matrices\",classy_NN.edge_matrices)\n",
    "print(\"final biases\",classy_NN.biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "these chunks implement classification of rap1 sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup = [68,20,10,1]\n",
    "alpha = 0.5\n",
    "lamba = 0 #0.1 is good\n",
    "batch_size = 10\n",
    "bias  = 1\n",
    "rap1_NN = NN.NeuralNetwork(setup,NN.activation,alpha,lamba,batch_size,bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "rap1_pos_list = io.import_positives('data/rap1-lieb-positives.txt')\n",
    "genom_neg_list = io.import_negatives('data/yeast-upstream-1k-negative.fa',17)\n",
    "rap1_test_list = io.import_positives('data/rap1-lieb-test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num batch is  14 20 20 20 20 20 20 20 2020 2020 20 20 14 20 20 20 20 20 20 20 20 2020 20 20 20 20 20 20 20 20 20 20 20 20 14 20 20 14 20\r"
     ]
    }
   ],
   "source": [
    "epoch_number = 10000 # the number of times through the whole data set\n",
    "cost_list = []\n",
    "for j in range(epoch_number):\n",
    "    batch_cycles = int(numpy.ceil(len(rap1_pos_list)/batch_size)) #the number of batches in data set for a given batch size\n",
    "    \n",
    "    for k in range(batch_cycles):\n",
    "        if k < batch_cycles-1:\n",
    "            training_list = rap1_pos_list[(k)*batch_size:(k+1)*batch_size]\n",
    "            rand_index    = int(numpy.floor(rand.random()*(len(genom_neg_list)-batch_size)))\n",
    "            #print(\"rand index is\", rand_index)\n",
    "            training_list = training_list + genom_neg_list[rand_index:rand_index+batch_size]\n",
    "            training_list = io.one_hot_encode(training_list)\n",
    "            #print(\"training list norm is\",len(training_list))\n",
    "            answer_list   = numpy.ones((batch_size))\n",
    "            answer_list   = numpy.concatenate((answer_list,numpy.zeros((batch_size))))\n",
    "        if k == batch_cycles-1:\n",
    "            size_temp     = len(rap1_pos_list[k*batch_size:])\n",
    "            training_list = rap1_pos_list[(k)*batch_size:]\n",
    "            and_index    = int(numpy.floor(rand.random()*(len(genom_neg_list)-size_temp)))\n",
    "            training_list = training_list + genom_neg_list[rand_index:rand_index+size_temp]\n",
    "            training_list = io.one_hot_encode(training_list)\n",
    "            #print(\"training list short is \",len(training_list))\n",
    "            answer_list   = numpy.ones((size_temp))\n",
    "            answer_list   = numpy.concatenate((answer_list,numpy.zeros((size_temp))))\n",
    "        \n",
    "        #print(k)\n",
    "        #print(training_list)\n",
    "        #print(answer_list)\n",
    "        rap1_NN.get_training_set(training_list,answer_list)\n",
    "        cost_list.append(rap1_NN.batch_descent())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0.\n",
      " 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      "final output [array([0.26009205, 0.56665375, 0.71717486, 0.65567088, 0.34895399,\n",
      "       0.73316433, 0.2696114 , 0.43231712, 0.28198917, 0.27403435,\n",
      "       0.57304264, 0.57161181, 0.24441525, 0.72175218, 0.27657997,\n",
      "       0.72076868, 0.73328369, 0.71276379, 0.7205313 , 0.26967169]), array([0.33915259, 0.39448661, 0.64240458, 0.24377999, 0.3182101 ,\n",
      "       0.16517164, 0.32831373, 0.91378808, 0.63071495, 0.73274587]), array([0.99614973])]\n",
      "final edge matrices [array([[ 0.06387376,  0.3523407 ,  0.27763144, ...,  0.2829721 ,\n",
      "         0.14397058,  0.11818834],\n",
      "       [ 0.00998827, -0.00983904, -0.00991425, ..., -0.01095335,\n",
      "        -0.0136587 ,  0.00118594],\n",
      "       [-0.02594391, -0.18292369, -0.13971268, ..., -0.14445318,\n",
      "        -0.05283753, -0.04692899],\n",
      "       ...,\n",
      "       [-0.06079823, -0.24404185, -0.17376569, ..., -0.18007655,\n",
      "        -0.09166998, -0.07398157],\n",
      "       [-0.05015435, -0.2724199 , -0.22142325, ..., -0.21940147,\n",
      "        -0.1144823 , -0.09632172],\n",
      "       [ 0.04692196,  0.31877162,  0.23065204, ...,  0.23329563,\n",
      "         0.10330859,  0.08686741]]), array([[ 0.29727781, -0.02504845, -0.17518447, -0.07113521,  0.04380051,\n",
      "        -0.1771204 ,  0.11908959,  0.0228002 ,  0.17670684,  0.13525265,\n",
      "        -0.03665062, -0.02547646,  0.33203087, -0.20090345,  0.24732827,\n",
      "        -0.19305945, -0.16700473, -0.22676757, -0.2562956 ,  0.26123469],\n",
      "       [ 0.17643925, -0.01435227, -0.10991434, -0.03343542,  0.03060326,\n",
      "        -0.10032503,  0.06194048,  0.01361466,  0.08442288,  0.07177267,\n",
      "        -0.01805271, -0.02924622,  0.20558318, -0.11838001,  0.12041391,\n",
      "        -0.12553373, -0.09055476, -0.15083101, -0.14344847,  0.15176836],\n",
      "       [-0.22627088,  0.05173412,  0.13662321,  0.04649798, -0.02588423,\n",
      "         0.14406095, -0.08665   ,  0.00958027, -0.10910229, -0.09890203,\n",
      "         0.0473629 ,  0.04847598, -0.2540595 ,  0.15231111, -0.17487089,\n",
      "         0.15243663,  0.11000876,  0.16462101,  0.20939293, -0.1994782 ],\n",
      "       [ 0.7362603 , -0.03632112, -0.36929968, -0.09600462,  0.0996465 ,\n",
      "        -0.36538361,  0.29359486,  0.04908429,  0.40595706,  0.29389765,\n",
      "        -0.0240702 , -0.03312745,  0.82468373, -0.4412055 ,  0.58686453,\n",
      "        -0.42208033, -0.32454593, -0.4774448 , -0.55498965,  0.62691549],\n",
      "       [ 0.38640131, -0.04069961, -0.21724593, -0.07162353,  0.04211387,\n",
      "        -0.20804505,  0.16679407,  0.01552349,  0.20983782,  0.13962086,\n",
      "        -0.03465076, -0.04147455,  0.41880209, -0.24776166,  0.31432733,\n",
      "        -0.24645368, -0.18434957, -0.26951553, -0.3045222 ,  0.32954009],\n",
      "       [ 1.19570252, -0.05774491, -0.5561581 , -0.12263176,  0.18705864,\n",
      "        -0.551981  ,  0.49450593,  0.08383358,  0.67191309,  0.47556389,\n",
      "        -0.05513086, -0.05242705,  1.35322333, -0.6872529 ,  0.91400082,\n",
      "        -0.66986044, -0.48471006, -0.72577479, -0.85682219,  1.0133637 ],\n",
      "       [ 0.33993734, -0.02161538, -0.17122446, -0.07132837,  0.03342354,\n",
      "        -0.19506628,  0.13762598,  0.01614966,  0.19869809,  0.12064143,\n",
      "        -0.03517629, -0.02854116,  0.39354382, -0.25298359,  0.27253675,\n",
      "        -0.21285536, -0.1663015 , -0.2482971 , -0.27729718,  0.26944294],\n",
      "       [-1.86735335,  0.08712896,  0.82869141,  0.18944816, -0.28359718,\n",
      "         0.83914249, -0.74111896, -0.14310422, -1.00119399, -0.6992129 ,\n",
      "         0.06196949,  0.08068082, -2.14232316,  1.02441356, -1.38214535,\n",
      "         1.00397799,  0.71589342,  1.12555591,  1.33219092, -1.50946815],\n",
      "       [-0.22996352,  0.02350714,  0.12170511,  0.0371481 , -0.0132808 ,\n",
      "         0.15804436, -0.08439881, -0.00897405, -0.13357437, -0.08615105,\n",
      "         0.03181918,  0.01843823, -0.25174193,  0.16577233, -0.17500183,\n",
      "         0.1593578 ,  0.12228719,  0.17573872,  0.18176977, -0.18749392],\n",
      "       [-0.61347057,  0.03219448,  0.31035665,  0.08196416, -0.09692535,\n",
      "         0.31548087, -0.25270146, -0.06264357, -0.36097622, -0.21614597,\n",
      "         0.03708968,  0.05316979, -0.6961767 ,  0.38323426, -0.46361098,\n",
      "         0.35625511,  0.27592846,  0.40508827,  0.4735538 , -0.51884749]]), array([[-0.78015709, -0.4218684 ,  0.70085764, -1.97237738, -0.98682289,\n",
      "        -3.40472511, -0.87415419,  6.03100298,  0.69500909,  1.75137134]])]\n",
      "final biases [array([ 0.51448395,  0.00697908, -0.19135253,  0.00111289,  0.01596783,\n",
      "       -0.2202812 ,  0.11783375, -0.02436696,  0.25246619,  0.12895487,\n",
      "        0.00103461, -0.01132372,  0.59887936, -0.28829783,  0.36570421,\n",
      "       -0.27861551, -0.17291424, -0.3190292 , -0.38394412,  0.43863095]), array([-0.00372935, -0.01291012,  0.00810719,  0.06317185,  0.02059526,\n",
      "        0.10449997,  0.0027321 , -0.22086303, -0.00188176, -0.04664816]), array([-0.0519834])]\n"
     ]
    }
   ],
   "source": [
    "pos_test = io.one_hot_encode([rap1_pos_list[100]])\n",
    "#pos_test = numpy.transpose(pos_test)\n",
    "pos_test = pos_test[0]\n",
    "print(pos_test)\n",
    "rap1_NN.get_single_input(pos_test)\n",
    "rap1_NN.feedforward()\n",
    "print(\"final output\",rap1_NN.layer_a)\n",
    "print(\"final edge matrices\",rap1_NN.edge_matrices)\n",
    "print(\"final biases\",rap1_NN.biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1.]\n",
      "final output [array([0.72863558, 0.47703861, 0.53428481, 0.36540405, 0.48309084,\n",
      "       0.62275252, 0.61099559, 0.51103906, 0.42716572, 0.51483941,\n",
      "       0.53641979, 0.54807336, 0.48875404, 0.48202713, 0.4980727 ,\n",
      "       0.5016603 , 0.38518337, 0.45967377, 0.6605626 , 0.55861594]), array([0.54513286, 0.46882699, 0.36612873, 0.29910017, 0.52631573,\n",
      "       0.82583073, 0.27211496, 0.20625491, 0.67059101, 0.76278744]), array([0.06574843])]\n",
      "final edge matrices [array([[ 1.06282603e-01,  2.67213153e-01,  1.30047339e-01, ...,\n",
      "         2.19378619e-01,  3.65996787e-02,  1.22441196e-01],\n",
      "       [ 4.54143096e-03,  1.97500930e-02, -1.45423372e-03, ...,\n",
      "         4.82414522e-03, -1.90970566e-02,  2.25483796e-03],\n",
      "       [ 4.51323976e-02,  1.33635681e-01,  6.27767401e-02, ...,\n",
      "         9.79037432e-02,  1.07619747e-05,  3.94412959e-02],\n",
      "       ...,\n",
      "       [-6.55739278e-02, -1.31486933e-01, -6.17296212e-02, ...,\n",
      "        -1.21816427e-01, -8.48651376e-03, -7.44352605e-02],\n",
      "       [ 9.04220275e-02,  2.07967546e-01,  9.81609673e-02, ...,\n",
      "         1.74353462e-01, -1.98199747e-03,  7.97319447e-02],\n",
      "       [ 2.50836469e-02,  1.33398603e-01,  6.41910938e-02, ...,\n",
      "         1.06452960e-01,  9.01752334e-04,  6.52759319e-02]]), array([[ 1.43134064e-01,  1.28715379e-02,  8.78638400e-02,\n",
      "        -1.30382290e-01,  2.83790701e-03,  1.15518579e-01,\n",
      "         1.12606151e-01, -6.48049356e-02, -1.10515602e-01,\n",
      "        -5.66134293e-02, -3.57814118e-02, -2.80747352e-02,\n",
      "         6.56719807e-02,  2.72420683e-02, -2.29226697e-02,\n",
      "        -7.84829669e-03, -1.32487911e-01, -9.87530896e-02,\n",
      "         1.32688981e-01,  9.15495845e-02],\n",
      "       [-8.45313238e-02, -3.01549454e-02, -3.96803821e-02,\n",
      "         6.81195374e-02,  1.40696959e-02, -4.90111490e-02,\n",
      "        -5.47236984e-02,  1.31064584e-02,  4.78940162e-02,\n",
      "         1.81537976e-02,  7.47068451e-03,  1.20613374e-02,\n",
      "        -2.71541920e-02, -6.46742926e-03,  2.41779239e-02,\n",
      "         4.95846221e-03,  6.79093302e-02,  4.05456601e-02,\n",
      "        -7.65382148e-02, -4.16093062e-02],\n",
      "       [-3.95981626e-01, -5.77216631e-02, -2.01956649e-01,\n",
      "         3.03572946e-01, -9.42862079e-03, -2.53980794e-01,\n",
      "        -2.64895460e-01,  1.35686515e-01,  2.41526528e-01,\n",
      "         8.32385049e-02,  6.64282955e-02,  5.20491307e-02,\n",
      "        -1.51282183e-01, -3.42029434e-02,  2.12314854e-02,\n",
      "         2.32338163e-02,  2.82569764e-01,  2.09072065e-01,\n",
      "        -3.03159025e-01, -2.10117532e-01],\n",
      "       [-5.72720253e-01, -8.44236817e-02, -2.95818971e-01,\n",
      "         4.17092036e-01,  8.31661994e-03, -3.72152081e-01,\n",
      "        -3.80861624e-01,  1.96502005e-01,  3.23602830e-01,\n",
      "         1.11457501e-01,  9.63511921e-02,  9.16826770e-02,\n",
      "        -2.09504000e-01, -6.25967418e-02,  2.36501820e-02,\n",
      "         3.39508730e-02,  4.00444278e-01,  2.90557019e-01,\n",
      "        -4.57015739e-01, -3.12813042e-01],\n",
      "       [ 1.23111235e-01,  4.10041634e-03,  3.98008625e-02,\n",
      "        -1.08427630e-01,  5.81008878e-03,  6.24795582e-02,\n",
      "         7.36030493e-02, -3.82818056e-02, -7.16015413e-02,\n",
      "        -3.84301309e-02, -2.14375513e-02, -2.36113824e-02,\n",
      "         4.13354976e-02,  6.98380255e-04,  9.61195495e-04,\n",
      "        -4.67605402e-03, -7.83600925e-02, -4.97058944e-02,\n",
      "         8.54785691e-02,  6.36402295e-02],\n",
      "       [ 9.73255837e-01,  1.39348959e-01,  4.76449151e-01,\n",
      "        -6.79455385e-01, -2.70133271e-03,  6.40451247e-01,\n",
      "         6.46224015e-01, -3.13010738e-01, -5.22695782e-01,\n",
      "        -1.48906306e-01, -1.59197045e-01, -1.17558141e-01,\n",
      "         3.42594190e-01,  1.30265656e-01, -1.25983173e-02,\n",
      "        -2.79400957e-02, -6.49696420e-01, -4.70537247e-01,\n",
      "         7.61881321e-01,  5.07906225e-01],\n",
      "       [-6.39354315e-01, -9.30244170e-02, -3.17627386e-01,\n",
      "         4.57648851e-01,  5.11887889e-03, -4.27568249e-01,\n",
      "        -4.43994558e-01,  2.21860405e-01,  3.81889618e-01,\n",
      "         1.33297224e-01,  1.05982272e-01,  8.53325136e-02,\n",
      "        -2.51744322e-01, -8.01448833e-02,  2.08726043e-03,\n",
      "         3.34136955e-02,  4.50679338e-01,  3.19798004e-01,\n",
      "        -5.05877176e-01, -3.44411267e-01],\n",
      "       [-8.47053253e-01, -1.15554505e-01, -4.20443327e-01,\n",
      "         5.98801444e-01, -2.62602864e-02, -5.66074543e-01,\n",
      "        -5.79479974e-01,  2.68717756e-01,  4.89953412e-01,\n",
      "         1.53991846e-01,  1.32395810e-01,  1.17995683e-01,\n",
      "        -3.14062617e-01, -1.11213842e-01,  5.26524255e-03,\n",
      "         4.94236656e-02,  5.56635352e-01,  4.27214627e-01,\n",
      "        -6.75080528e-01, -4.44302583e-01],\n",
      "       [ 4.84696510e-01,  7.07205111e-02,  2.34794879e-01,\n",
      "        -3.54230558e-01, -1.23397838e-02,  3.33094454e-01,\n",
      "         3.33710868e-01, -1.84426649e-01, -2.87563242e-01,\n",
      "        -9.68931404e-02, -8.92101083e-02, -8.34964999e-02,\n",
      "         2.02310032e-01,  6.54151947e-02, -1.35312649e-02,\n",
      "        -2.84972806e-02, -3.56818323e-01, -2.46848263e-01,\n",
      "         3.73962902e-01,  2.86997132e-01],\n",
      "       [ 7.71074073e-01,  1.04391396e-01,  3.66356825e-01,\n",
      "        -5.31041261e-01, -1.91107016e-03,  4.86634901e-01,\n",
      "         4.94570432e-01, -2.38471327e-01, -4.37156026e-01,\n",
      "        -1.33194525e-01, -1.20036386e-01, -9.01127630e-02,\n",
      "         2.72764674e-01,  1.07058378e-01, -5.13386476e-03,\n",
      "        -2.63909312e-02, -5.09515292e-01, -3.82367092e-01,\n",
      "         5.95161074e-01,  3.94453328e-01]]), array([[-0.37801413,  0.20199642,  0.92152812,  1.33928192, -0.24841672,\n",
      "        -2.29129835,  1.51482634,  2.01747231, -1.13031042, -1.74773231]])]\n",
      "final biases [array([ 0.32084865, -0.00551162,  0.10798882, -0.20203203, -0.00798271,\n",
      "        0.19534867,  0.16826117, -0.04313428, -0.128614  , -0.00886912,\n",
      "        0.00362706, -0.00931296,  0.06986809,  0.00653123, -0.00313673,\n",
      "       -0.0036163 , -0.18403495, -0.11435867,  0.24781611,  0.1288809 ]), array([ 0.00099237, -0.01166095, -0.00989854, -0.03330513, -0.01791186,\n",
      "        0.06141176, -0.03505845, -0.0487854 ,  0.01734958,  0.03075419]), array([0.00525328])]\n"
     ]
    }
   ],
   "source": [
    "neg_test = io.one_hot_encode([genom_neg_list[100]])\n",
    "#pos_test = numpy.transpose(pos_test)\n",
    "neg_test = neg_test[0]\n",
    "print(neg_test)\n",
    "rap1_NN.get_single_input(neg_test)\n",
    "rap1_NN.feedforward()\n",
    "print(\"final output\",rap1_NN.layer_a)\n",
    "print(\"final edge matrices\",rap1_NN.edge_matrices)\n",
    "print(\"final biases\",rap1_NN.biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores = []\n",
    "for i in range(len(rap1_test_list)):\n",
    "    test_test = io.one_hot_encode([rap1_test_list[i]])\n",
    "    test_test = test_test[0]\n",
    "    rap1_NN.get_single_input(test_test)\n",
    "    rap1_NN.feedforward()\n",
    "    test_scores.append(rap1_NN.layer_a[2][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_bins = 20\n",
    "n, bins, patches = plt.hist(test_scores, num_bins, facecolor = 'blue', alpha = 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
